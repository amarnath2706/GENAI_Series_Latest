{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25dbac4304d9480480a0bbefc9f21646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_756792d44e464c32b1545ccc60a40623",
              "IPY_MODEL_cea27340819f43acbca89149e7cf0dd8",
              "IPY_MODEL_73bcaa5b4a964d0c80513d201f88e73b"
            ],
            "layout": "IPY_MODEL_83e9e86eef7e4b0aabea6e7d887e5a67"
          }
        },
        "756792d44e464c32b1545ccc60a40623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f646f105114ce39164217fd1f44eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_85395c7761284c4497c9aa39fe30c3e7",
            "value": "config.json: 100%"
          }
        },
        "cea27340819f43acbca89149e7cf0dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d189b139cf24f07b8e928189d502a48",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68b2666071bf4246988d7970e4ad7dc3",
            "value": 1585
          }
        },
        "73bcaa5b4a964d0c80513d201f88e73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024c1c19a2e04ebe8bf9efe26de6f431",
            "placeholder": "​",
            "style": "IPY_MODEL_8fe5d2809a0f4c80a0f935798b52bc00",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 37.8kB/s]"
          }
        },
        "83e9e86eef7e4b0aabea6e7d887e5a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f646f105114ce39164217fd1f44eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85395c7761284c4497c9aa39fe30c3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d189b139cf24f07b8e928189d502a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b2666071bf4246988d7970e4ad7dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "024c1c19a2e04ebe8bf9efe26de6f431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe5d2809a0f4c80a0f935798b52bc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac49d22edf9b484eb0b839936d1fdf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_651c29eeaa42442ea23b70ddc9b4451c",
              "IPY_MODEL_acc8cafdf3c6425c8ad0de3b301a338b",
              "IPY_MODEL_0adaee8b45e74a0c956bc750230c1202"
            ],
            "layout": "IPY_MODEL_dcf2fee199574c17b378a0dff91b1496"
          }
        },
        "651c29eeaa42442ea23b70ddc9b4451c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972ea246efd8406a8dbf7ea0ed2cd20a",
            "placeholder": "​",
            "style": "IPY_MODEL_1f1a98a088ef408391d0b015e5b2bf36",
            "value": "model.safetensors: 100%"
          }
        },
        "acc8cafdf3c6425c8ad0de3b301a338b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c514d00b5df04911ad72edf8e1641573",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df9112360eec443c9924bb2ab9d2d7c0",
            "value": 1625222120
          }
        },
        "0adaee8b45e74a0c956bc750230c1202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e50eac891a4331b6a7b15d6660f2fa",
            "placeholder": "​",
            "style": "IPY_MODEL_48a6988319a04414a76e178d3e1614d2",
            "value": " 1.63G/1.63G [00:12&lt;00:00, 189MB/s]"
          }
        },
        "dcf2fee199574c17b378a0dff91b1496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972ea246efd8406a8dbf7ea0ed2cd20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1a98a088ef408391d0b015e5b2bf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c514d00b5df04911ad72edf8e1641573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9112360eec443c9924bb2ab9d2d7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3e50eac891a4331b6a7b15d6660f2fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a6988319a04414a76e178d3e1614d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d2e118e266e41a794b98670cf34b6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff75c20292b74afc99e1131278d48e66",
              "IPY_MODEL_bb4378917d0c47f2b5b50d3616780d9a",
              "IPY_MODEL_63285348262f49aabb60384c5e0901fb"
            ],
            "layout": "IPY_MODEL_d95709ab1cc7431381f7b300bd4a538b"
          }
        },
        "ff75c20292b74afc99e1131278d48e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d1d1afa8a542eead184ac530b1af86",
            "placeholder": "​",
            "style": "IPY_MODEL_c042312422284fe99b71520e1fab9d05",
            "value": "generation_config.json: 100%"
          }
        },
        "bb4378917d0c47f2b5b50d3616780d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e808542319046c2b511f4304cbf37fd",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70816c52722745e5bc87cbba598450aa",
            "value": 363
          }
        },
        "63285348262f49aabb60384c5e0901fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5410dd2959824c26828936ea2e76603f",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ad3c4f1d094918ad77e3da4804e8e3",
            "value": " 363/363 [00:00&lt;00:00, 5.81kB/s]"
          }
        },
        "d95709ab1cc7431381f7b300bd4a538b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d1d1afa8a542eead184ac530b1af86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c042312422284fe99b71520e1fab9d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e808542319046c2b511f4304cbf37fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70816c52722745e5bc87cbba598450aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5410dd2959824c26828936ea2e76603f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ad3c4f1d094918ad77e3da4804e8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89a3e63d713a485386d1dadc0703009a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81460e2f3ff042bc953d68eb24c7c9ab",
              "IPY_MODEL_7dcf195e7c264f96948583477c8e6a7c",
              "IPY_MODEL_bb3ea96f29a34fde89a54e58b2dc8f7c"
            ],
            "layout": "IPY_MODEL_e15985be617e4133a503c435fac43918"
          }
        },
        "81460e2f3ff042bc953d68eb24c7c9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f24720e71ec2432f9d04315d25fe34d9",
            "placeholder": "​",
            "style": "IPY_MODEL_87646379621748ec8b1f7c6b09d0a77b",
            "value": "vocab.json: 100%"
          }
        },
        "7dcf195e7c264f96948583477c8e6a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e825d2fc008b4821bb801f1b7f231554",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e5b53dd12ec4988966e21fd79462a8b",
            "value": 898823
          }
        },
        "bb3ea96f29a34fde89a54e58b2dc8f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46df9358958e4547964ca9a1297c82ff",
            "placeholder": "​",
            "style": "IPY_MODEL_f8fe978608ba47d9b8939f4f1602a7a0",
            "value": " 899k/899k [00:00&lt;00:00, 5.40MB/s]"
          }
        },
        "e15985be617e4133a503c435fac43918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24720e71ec2432f9d04315d25fe34d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87646379621748ec8b1f7c6b09d0a77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e825d2fc008b4821bb801f1b7f231554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e5b53dd12ec4988966e21fd79462a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46df9358958e4547964ca9a1297c82ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fe978608ba47d9b8939f4f1602a7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e12f9a30874de0bd9cbd2d0ca9d28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b298ebc6280249bc988399f4ed6293cf",
              "IPY_MODEL_e648065b4ce145cebc71c212581a7491",
              "IPY_MODEL_f2b85eca424545b6830ab07aa63ae7c6"
            ],
            "layout": "IPY_MODEL_62b5c2750ed947629e18f6bf097198f5"
          }
        },
        "b298ebc6280249bc988399f4ed6293cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a7f78d363a4c8fa1a79b81b039df6e",
            "placeholder": "​",
            "style": "IPY_MODEL_ffed1af35cb74934a74dd09cea995877",
            "value": "merges.txt: 100%"
          }
        },
        "e648065b4ce145cebc71c212581a7491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee00c7fea4a74c4581932443771c5eed",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea40a9a0cb9c4232ab6f69f8932d3000",
            "value": 456318
          }
        },
        "f2b85eca424545b6830ab07aa63ae7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6d61063ef814ebfb26a2aa1f33f9548",
            "placeholder": "​",
            "style": "IPY_MODEL_b478776ca71a4e64a6b64e89b7c640c3",
            "value": " 456k/456k [00:00&lt;00:00, 13.1MB/s]"
          }
        },
        "62b5c2750ed947629e18f6bf097198f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a7f78d363a4c8fa1a79b81b039df6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffed1af35cb74934a74dd09cea995877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee00c7fea4a74c4581932443771c5eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea40a9a0cb9c4232ab6f69f8932d3000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6d61063ef814ebfb26a2aa1f33f9548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b478776ca71a4e64a6b64e89b7c640c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f77014c86b8460b96a14f70f93d04fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cf44a4d03a34273aa3771b42acda1b5",
              "IPY_MODEL_619425857d924afbb4f0314e6005afcc",
              "IPY_MODEL_0f0f022961f445e4ac408907ef594b07"
            ],
            "layout": "IPY_MODEL_a1e24b3197db4885b21fb103736d6af4"
          }
        },
        "4cf44a4d03a34273aa3771b42acda1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5317495057ab41158c91e9652d8fd070",
            "placeholder": "​",
            "style": "IPY_MODEL_42bcc8134f7e46f69bba3435d0d80b91",
            "value": "tokenizer.json: 100%"
          }
        },
        "619425857d924afbb4f0314e6005afcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1010db5ed70a4c5c93821f30d4d6827a",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d828f9ab1c424abaffb90fd587ebb2",
            "value": 1355863
          }
        },
        "0f0f022961f445e4ac408907ef594b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e687b3d9864dbd97544efe65e4f9aa",
            "placeholder": "​",
            "style": "IPY_MODEL_d547b2f9ebb047c5a9d73b0e0ceca14b",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 24.0MB/s]"
          }
        },
        "a1e24b3197db4885b21fb103736d6af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5317495057ab41158c91e9652d8fd070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42bcc8134f7e46f69bba3435d0d80b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1010db5ed70a4c5c93821f30d4d6827a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d828f9ab1c424abaffb90fd587ebb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35e687b3d9864dbd97544efe65e4f9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d547b2f9ebb047c5a9d73b0e0ceca14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRz6Hhmza5y4",
        "outputId": "6af7ef12-6761-475d-99ca-bd806abfcda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.10/dist-packages (from arxiv) (2.32.3)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (2024.8.30)\n",
            "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=204bab4f46fde21978ae28c77ba0249730e945ae6843da6a0323da198b16d3a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arxiv\n",
        "\n",
        "#arxiv is a website where we can get many research papers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yxl37f6rbT2_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Query to fetch AI related papers from arxiv\n",
        "query = 'AI or artificial intelligence OR MACHINE learnin'\n",
        "search = arxiv.Search(query = query, max_results=10, sort_by = arxiv.SortCriterion.SubmittedDate)\n",
        "\n",
        "#Fetch papers\n",
        "papers = []\n",
        "for result in search.results():\n",
        "  papers.append(\n",
        "      {\n",
        "          'published':result.published,\n",
        "          'title' : result.title,\n",
        "          'abstract' : result.summary,\n",
        "          'categories' : result.categories\n",
        "      }\n",
        "  )\n",
        "\n",
        "\n",
        "#Convert to Dataframe\n",
        "df = pd.DataFrame(papers)\n",
        "\n",
        "pd.set_option('display.max_colwidth',None)\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GCKPRxL6bYdD",
        "outputId": "faa8807d-67ef-4b8b-d3e9-13ab47513375"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c935efa50220>:7: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  published  \\\n",
              "0 2024-10-17 17:59:59+00:00   \n",
              "1 2024-10-17 17:59:55+00:00   \n",
              "2 2024-10-17 17:59:35+00:00   \n",
              "3 2024-10-17 17:59:34+00:00   \n",
              "4 2024-10-17 17:59:25+00:00   \n",
              "5 2024-10-17 17:59:24+00:00   \n",
              "6 2024-10-17 17:59:09+00:00   \n",
              "7 2024-10-17 17:59:03+00:00   \n",
              "8 2024-10-17 17:59:02+00:00   \n",
              "9 2024-10-17 17:59:01+00:00   \n",
              "\n",
              "                                                                                    title  \\\n",
              "0    Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens   \n",
              "1                             VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding   \n",
              "2             How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs   \n",
              "3  A Fourier analysis framework for approximate classical simulations of quantum circuits   \n",
              "4            Diffusing States and Matching Scores: A New Framework for Imitation Learning   \n",
              "5                        Can MLLMs Understand the Deep Implication Behind Chinese Images?   \n",
              "6             AutoAL: Automated Active Learning with Differentiable Query Strategy Search   \n",
              "7                                                Retrospective Learning from Interactions   \n",
              "8                   Influence Functions for Scalable Data Attribution in Diffusion Models   \n",
              "9                            From Gradient Clipping to Normalization for Heavy Tailed SGD   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    abstract  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Scaling up autoregressive models in vision has not proven as beneficial as in\\nlarge language models. In this work, we investigate this scaling problem in the\\ncontext of text-to-image generation, focusing on two critical factors: whether\\nmodels use discrete or continuous tokens, and whether tokens are generated in a\\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\\nOur empirical results show that, while all models scale effectively in terms of\\nvalidation loss, their evaluation performance -- measured by FID, GenEval\\nscore, and visual quality -- follows different trends. Models based on\\ncontinuous tokens achieve significantly better visual quality than those using\\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\\nsignificantly affect the GenEval score: random-order models achieve notably\\nbetter GenEval scores compared to raster-order models. Inspired by these\\nfindings, we train Fluid, a random-order autoregressive model on continuous\\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\\nfindings and results will encourage future efforts to further bridge the\\nscaling gap between vision and language models.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3D visual grounding is crucial for robots, requiring integration of natural\\nlanguage and 3D scene understanding. Traditional methods depending on\\nsupervised learning with 3D point clouds are limited by scarce datasets.\\nRecently zero-shot methods leveraging LLMs have been proposed to address the\\ndata issue. While effective, these methods only use object-centric information,\\nlimiting their ability to handle complex queries. In this work, we present\\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\\ndynamically stitches image sequences, employs a grounding and feedback scheme\\nto find the target object, and uses a multi-view ensemble projection to\\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\\ngeometry or object priors. Codes are available at\\nhttps://github.com/OpenRobotLab/VLM-Grounder .   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Despite the remarkable success of Transformer-based Large Language Models\\n(LLMs) across various domains, understanding and enhancing their mathematical\\ncapabilities remains a significant challenge. In this paper, we conduct a\\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\\nfocus on their arithmetic performances. We identify numerical precision as a\\nkey factor that influences their effectiveness in mathematical tasks. Our\\nresults show that Transformers operating with low numerical precision fail to\\naddress arithmetic tasks, such as iterated addition and integer multiplication,\\nunless the model size grows super-polynomially with respect to the input\\nlength. In contrast, Transformers with standard numerical precision can\\nefficiently handle these tasks with significantly smaller model sizes. We\\nfurther support our theoretical findings through empirical experiments that\\nexplore the impact of varying numerical precision on arithmetic tasks,\\nproviding valuable insights for improving the mathematical reasoning\\ncapabilities of LLMs.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  What makes a class of quantum circuits efficiently classically simulable on\\naverage? I present a framework that applies harmonic analysis of groups to\\ncircuits with a structure encoded by group parameters. Expanding the circuits\\nin a suitable truncated multi-path operator basis gives algorithms to evaluate\\nthe Fourier coefficients of output distributions or expectation values that are\\nviewed as functions on the group. Under certain conditions, a truncated Fourier\\nseries can be efficiently estimated with guaranteed mean-square convergence.\\nFor classes of noisy circuits, it leads to algorithms for sampling and mean\\nvalue estimation under error models with a spectral gap, where the complexity\\nincreases exponentially with the gap's inverse and polynomially with the\\ncircuit's size. This approach unifies and extends existing algorithms for noisy\\nparametrised or random circuits using Pauli basis paths. For classes of\\nnoiseless circuits, mean values satisfying Lipschitz continuity can be on\\naverage approximated using efficient sparse Fourier decompositions. I also\\ndiscuss generalisations to homogeneous spaces, qudit systems and a way to\\nanalyse random circuits via matrix coefficients of irreducible representations.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Adversarial Imitation Learning is traditionally framed as a two-player\\nzero-sum game between a learner and an adversarially chosen cost function, and\\ncan therefore be thought of as the sequential generalization of a Generative\\nAdversarial Network (GAN). A prominent example of this framework is Generative\\nAdversarial Imitation Learning (GAIL). However, in recent years, diffusion\\nmodels have emerged as a non-adversarial alternative to GANs that merely\\nrequire training a score function via regression, yet produce generations of a\\nhigher quality. In response, we investigate how to lift insights from diffusion\\nmodeling to the sequential setting. We propose diffusing states and performing\\nscore-matching along diffused states to measure the discrepancy between the\\nexpert's and learner's states. Thus, our approach only requires training score\\nfunctions to predict noises via standard regression, making it significantly\\neasier and more stable to train than adversarial methods. Theoretically, we\\nprove first- and second-order instance-dependent bounds with linear scaling in\\nthe horizon, proving that our approach avoids the compounding errors that\\nstymie offline approaches to imitation learning. Empirically, we show our\\napproach outperforms GAN-style imitation learning baselines across various\\ncontinuous control problems, including complex tasks like controlling humanoids\\nto walk, sit, and crawl.   \n",
              "5  As the capabilities of Multimodal Large Language Models (MLLMs) continue to\\nimprove, the need for higher-order capability evaluation of MLLMs is\\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\\nperception and understanding of Chinese visual content. To fill the gap, we\\nintroduce the **C**hinese **I**mage **I**mplication understanding\\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\\nout in several ways compared to existing benchmarks. Firstly, to ensure the\\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\\nChinese Internet and manually reviewed, with corresponding answers also\\nmanually crafted. Additionally, CII-Bench incorporates images that represent\\nChinese traditional culture, such as famous Chinese traditional paintings,\\nwhich can deeply reflect the model's understanding of Chinese traditional\\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\\nhave made significant findings. Initially, a substantial gap is observed\\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\\nculture images, suggesting limitations in their ability to understand\\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\\nculture. Finally, it is observed that most models exhibit enhanced accuracy\\nwhen image emotion hints are incorporated into the prompts. We believe that\\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\\nand Chinese-specific images, advancing the journey towards expert artificial\\ngeneral intelligence (AGI). Our project is publicly available at\\nhttps://cii-bench.github.io/.   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                     As deep learning continues to evolve, the need for data efficiency becomes\\nincreasingly important. Considering labeling large datasets is both\\ntime-consuming and expensive, active learning (AL) provides a promising\\nsolution to this challenge by iteratively selecting the most informative\\nsubsets of examples to train deep neural networks, thereby reducing the\\nlabeling cost. However, the effectiveness of different AL algorithms can vary\\nsignificantly across data scenarios, and determining which AL algorithm best\\nfits a given task remains a challenging problem. This work presents the first\\ndifferentiable AL strategy search method, named AutoAL, which is designed on\\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\\nnamed SearchNet and FitNet, which are optimized concurrently under a\\ndifferentiable bi-level optimization framework. For any given task, SearchNet\\nand FitNet are iteratively co-optimized using the labeled data, learning how\\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\\nfor querying their annotations, enabling efficient training of the task model.\\nExperimental results demonstrate that AutoAL consistently achieves superior\\naccuracy compared to all candidate AL algorithms and other selective AL\\napproaches, showcasing its potential for adapting and integrating multiple\\nexisting AL methods across diverse tasks and domains. Code will be available\\nat: https://github.com/haizailache999/AutoAL.   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Multi-turn interactions between large language models (LLMs) and users\\nnaturally include implicit feedback signals. If an LLM responds in an\\nunexpected way to an instruction, the user is likely to signal it by rephrasing\\nthe request, expressing frustration, or pivoting to an alternative task. Such\\nsignals are task-independent and occupy a relatively constrained subspace of\\nlanguage, allowing the LLM to identify them even if it fails on the actual\\ntask. This creates an avenue for continually learning from interactions without\\nadditional annotations. We introduce ReSpect, a method to learn from such\\nsignals in past interactions via retrospection. We deploy ReSpect in a new\\nmultimodal interaction scenario, where humans instruct an LLM to solve an\\nabstract reasoning task with a combinatorial solution space. Through thousands\\nof interactions with humans, we show how ReSpect gradually improves task\\ncompletion rate from 31% to 82%, all without any external annotation.   \n",
              "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Diffusion models have led to significant advancements in generative\\nmodelling. Yet their widespread adoption poses challenges regarding data\\nattribution and interpretability. In this paper, we aim to help address such\\nchallenges in diffusion models by developing an \\textit{influence functions}\\nframework. Influence function-based data attribution methods approximate how a\\nmodel's output would have changed if some training data were removed. In\\nsupervised learning, this is usually used for predicting how the loss on a\\nparticular example would change. For diffusion models, we focus on predicting\\nthe change in the probability of generating a particular example via several\\nproxy measurements. We show how to formulate influence functions for such\\nquantities and how previously proposed methods can be interpreted as particular\\ndesign choices in our framework. To ensure scalability of the Hessian\\ncomputations in influence functions, we systematically develop K-FAC\\napproximations based on generalised Gauss-Newton matrices specifically tailored\\nto diffusion models. We recast previously proposed methods as specific design\\nchoices in our framework and show that our recommended method outperforms\\nprevious data attribution approaches on common evaluations, such as the Linear\\nData-modelling Score (LDS) or retraining without top influences, without the\\nneed for method-specific hyperparameter tuning.   \n",
              "9                                                                                                Recent empirical evidence indicates that many machine learning applications\\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\\nof bounded variance in stochastic optimization. Gradient clipping has emerged\\nas a popular tool to handle this heavy-tailed noise, as it achieves good\\nperformance in this setting both theoretically and practically. However, our\\ncurrent theoretical understanding of non-convex gradient clipping has three\\nmain shortcomings. First, the theory hinges on large, increasing clipping\\nthresholds, which are in stark contrast to the small constant clipping\\nthresholds employed in practice. Second, clipping thresholds require knowledge\\nof problem-dependent parameters to guarantee convergence. Lastly, even with\\nthis knowledge, current sampling complexity upper bounds for the method are\\nsub-optimal in nearly all parameters. To address these issues, we study\\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\\nsample complexity for NSGD of\\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\\nby providing a matching algorithm-specific lower bound. In the setting where\\nall problem parameters are known, we show this complexity is improved to\\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\\npreviously known lower bound for all first-order methods in all problem\\ndependent parameters. Finally, we establish high-probability convergence of\\nNSGD with a mild logarithmic dependence on the failure probability. Our work\\ncomplements the studies of gradient clipping under heavy tailed noise improving\\nthe sample complexities of existing algorithms and offering an alternative\\nmechanism to achieve high probability convergence.   \n",
              "\n",
              "                       categories  \n",
              "0                  [cs.CV, cs.LG]  \n",
              "1                  [cs.CV, cs.RO]  \n",
              "2  [cs.LG, cs.AI, cs.CL, stat.ML]  \n",
              "3                      [quant-ph]  \n",
              "4                         [cs.LG]  \n",
              "5    [cs.CL, cs.AI, cs.CV, cs.CY]  \n",
              "6                         [cs.LG]  \n",
              "7    [cs.CL, cs.AI, cs.CV, cs.LG]  \n",
              "8                  [cs.LG, cs.AI]  \n",
              "9       [math.OC, cs.LG, stat.ML]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1305b876-892e-4f29-8915-c61c52da1782\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-10-17 17:59:59+00:00</td>\n",
              "      <td>Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens</td>\n",
              "      <td>Scaling up autoregressive models in vision has not proven as beneficial as in\\nlarge language models. In this work, we investigate this scaling problem in the\\ncontext of text-to-image generation, focusing on two critical factors: whether\\nmodels use discrete or continuous tokens, and whether tokens are generated in a\\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\\nOur empirical results show that, while all models scale effectively in terms of\\nvalidation loss, their evaluation performance -- measured by FID, GenEval\\nscore, and visual quality -- follows different trends. Models based on\\ncontinuous tokens achieve significantly better visual quality than those using\\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\\nsignificantly affect the GenEval score: random-order models achieve notably\\nbetter GenEval scores compared to raster-order models. Inspired by these\\nfindings, we train Fluid, a random-order autoregressive model on continuous\\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\\nfindings and results will encourage future efforts to further bridge the\\nscaling gap between vision and language models.</td>\n",
              "      <td>[cs.CV, cs.LG]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-10-17 17:59:55+00:00</td>\n",
              "      <td>VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding</td>\n",
              "      <td>3D visual grounding is crucial for robots, requiring integration of natural\\nlanguage and 3D scene understanding. Traditional methods depending on\\nsupervised learning with 3D point clouds are limited by scarce datasets.\\nRecently zero-shot methods leveraging LLMs have been proposed to address the\\ndata issue. While effective, these methods only use object-centric information,\\nlimiting their ability to handle complex queries. In this work, we present\\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\\ndynamically stitches image sequences, employs a grounding and feedback scheme\\nto find the target object, and uses a multi-view ensemble projection to\\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\\ngeometry or object priors. Codes are available at\\nhttps://github.com/OpenRobotLab/VLM-Grounder .</td>\n",
              "      <td>[cs.CV, cs.RO]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-10-17 17:59:35+00:00</td>\n",
              "      <td>How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs</td>\n",
              "      <td>Despite the remarkable success of Transformer-based Large Language Models\\n(LLMs) across various domains, understanding and enhancing their mathematical\\ncapabilities remains a significant challenge. In this paper, we conduct a\\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\\nfocus on their arithmetic performances. We identify numerical precision as a\\nkey factor that influences their effectiveness in mathematical tasks. Our\\nresults show that Transformers operating with low numerical precision fail to\\naddress arithmetic tasks, such as iterated addition and integer multiplication,\\nunless the model size grows super-polynomially with respect to the input\\nlength. In contrast, Transformers with standard numerical precision can\\nefficiently handle these tasks with significantly smaller model sizes. We\\nfurther support our theoretical findings through empirical experiments that\\nexplore the impact of varying numerical precision on arithmetic tasks,\\nproviding valuable insights for improving the mathematical reasoning\\ncapabilities of LLMs.</td>\n",
              "      <td>[cs.LG, cs.AI, cs.CL, stat.ML]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-10-17 17:59:34+00:00</td>\n",
              "      <td>A Fourier analysis framework for approximate classical simulations of quantum circuits</td>\n",
              "      <td>What makes a class of quantum circuits efficiently classically simulable on\\naverage? I present a framework that applies harmonic analysis of groups to\\ncircuits with a structure encoded by group parameters. Expanding the circuits\\nin a suitable truncated multi-path operator basis gives algorithms to evaluate\\nthe Fourier coefficients of output distributions or expectation values that are\\nviewed as functions on the group. Under certain conditions, a truncated Fourier\\nseries can be efficiently estimated with guaranteed mean-square convergence.\\nFor classes of noisy circuits, it leads to algorithms for sampling and mean\\nvalue estimation under error models with a spectral gap, where the complexity\\nincreases exponentially with the gap's inverse and polynomially with the\\ncircuit's size. This approach unifies and extends existing algorithms for noisy\\nparametrised or random circuits using Pauli basis paths. For classes of\\nnoiseless circuits, mean values satisfying Lipschitz continuity can be on\\naverage approximated using efficient sparse Fourier decompositions. I also\\ndiscuss generalisations to homogeneous spaces, qudit systems and a way to\\nanalyse random circuits via matrix coefficients of irreducible representations.</td>\n",
              "      <td>[quant-ph]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-10-17 17:59:25+00:00</td>\n",
              "      <td>Diffusing States and Matching Scores: A New Framework for Imitation Learning</td>\n",
              "      <td>Adversarial Imitation Learning is traditionally framed as a two-player\\nzero-sum game between a learner and an adversarially chosen cost function, and\\ncan therefore be thought of as the sequential generalization of a Generative\\nAdversarial Network (GAN). A prominent example of this framework is Generative\\nAdversarial Imitation Learning (GAIL). However, in recent years, diffusion\\nmodels have emerged as a non-adversarial alternative to GANs that merely\\nrequire training a score function via regression, yet produce generations of a\\nhigher quality. In response, we investigate how to lift insights from diffusion\\nmodeling to the sequential setting. We propose diffusing states and performing\\nscore-matching along diffused states to measure the discrepancy between the\\nexpert's and learner's states. Thus, our approach only requires training score\\nfunctions to predict noises via standard regression, making it significantly\\neasier and more stable to train than adversarial methods. Theoretically, we\\nprove first- and second-order instance-dependent bounds with linear scaling in\\nthe horizon, proving that our approach avoids the compounding errors that\\nstymie offline approaches to imitation learning. Empirically, we show our\\napproach outperforms GAN-style imitation learning baselines across various\\ncontinuous control problems, including complex tasks like controlling humanoids\\nto walk, sit, and crawl.</td>\n",
              "      <td>[cs.LG]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2024-10-17 17:59:24+00:00</td>\n",
              "      <td>Can MLLMs Understand the Deep Implication Behind Chinese Images?</td>\n",
              "      <td>As the capabilities of Multimodal Large Language Models (MLLMs) continue to\\nimprove, the need for higher-order capability evaluation of MLLMs is\\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\\nperception and understanding of Chinese visual content. To fill the gap, we\\nintroduce the **C**hinese **I**mage **I**mplication understanding\\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\\nout in several ways compared to existing benchmarks. Firstly, to ensure the\\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\\nChinese Internet and manually reviewed, with corresponding answers also\\nmanually crafted. Additionally, CII-Bench incorporates images that represent\\nChinese traditional culture, such as famous Chinese traditional paintings,\\nwhich can deeply reflect the model's understanding of Chinese traditional\\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\\nhave made significant findings. Initially, a substantial gap is observed\\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\\nculture images, suggesting limitations in their ability to understand\\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\\nculture. Finally, it is observed that most models exhibit enhanced accuracy\\nwhen image emotion hints are incorporated into the prompts. We believe that\\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\\nand Chinese-specific images, advancing the journey towards expert artificial\\ngeneral intelligence (AGI). Our project is publicly available at\\nhttps://cii-bench.github.io/.</td>\n",
              "      <td>[cs.CL, cs.AI, cs.CV, cs.CY]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2024-10-17 17:59:09+00:00</td>\n",
              "      <td>AutoAL: Automated Active Learning with Differentiable Query Strategy Search</td>\n",
              "      <td>As deep learning continues to evolve, the need for data efficiency becomes\\nincreasingly important. Considering labeling large datasets is both\\ntime-consuming and expensive, active learning (AL) provides a promising\\nsolution to this challenge by iteratively selecting the most informative\\nsubsets of examples to train deep neural networks, thereby reducing the\\nlabeling cost. However, the effectiveness of different AL algorithms can vary\\nsignificantly across data scenarios, and determining which AL algorithm best\\nfits a given task remains a challenging problem. This work presents the first\\ndifferentiable AL strategy search method, named AutoAL, which is designed on\\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\\nnamed SearchNet and FitNet, which are optimized concurrently under a\\ndifferentiable bi-level optimization framework. For any given task, SearchNet\\nand FitNet are iteratively co-optimized using the labeled data, learning how\\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\\nfor querying their annotations, enabling efficient training of the task model.\\nExperimental results demonstrate that AutoAL consistently achieves superior\\naccuracy compared to all candidate AL algorithms and other selective AL\\napproaches, showcasing its potential for adapting and integrating multiple\\nexisting AL methods across diverse tasks and domains. Code will be available\\nat: https://github.com/haizailache999/AutoAL.</td>\n",
              "      <td>[cs.LG]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2024-10-17 17:59:03+00:00</td>\n",
              "      <td>Retrospective Learning from Interactions</td>\n",
              "      <td>Multi-turn interactions between large language models (LLMs) and users\\nnaturally include implicit feedback signals. If an LLM responds in an\\nunexpected way to an instruction, the user is likely to signal it by rephrasing\\nthe request, expressing frustration, or pivoting to an alternative task. Such\\nsignals are task-independent and occupy a relatively constrained subspace of\\nlanguage, allowing the LLM to identify them even if it fails on the actual\\ntask. This creates an avenue for continually learning from interactions without\\nadditional annotations. We introduce ReSpect, a method to learn from such\\nsignals in past interactions via retrospection. We deploy ReSpect in a new\\nmultimodal interaction scenario, where humans instruct an LLM to solve an\\nabstract reasoning task with a combinatorial solution space. Through thousands\\nof interactions with humans, we show how ReSpect gradually improves task\\ncompletion rate from 31% to 82%, all without any external annotation.</td>\n",
              "      <td>[cs.CL, cs.AI, cs.CV, cs.LG]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2024-10-17 17:59:02+00:00</td>\n",
              "      <td>Influence Functions for Scalable Data Attribution in Diffusion Models</td>\n",
              "      <td>Diffusion models have led to significant advancements in generative\\nmodelling. Yet their widespread adoption poses challenges regarding data\\nattribution and interpretability. In this paper, we aim to help address such\\nchallenges in diffusion models by developing an \\textit{influence functions}\\nframework. Influence function-based data attribution methods approximate how a\\nmodel's output would have changed if some training data were removed. In\\nsupervised learning, this is usually used for predicting how the loss on a\\nparticular example would change. For diffusion models, we focus on predicting\\nthe change in the probability of generating a particular example via several\\nproxy measurements. We show how to formulate influence functions for such\\nquantities and how previously proposed methods can be interpreted as particular\\ndesign choices in our framework. To ensure scalability of the Hessian\\ncomputations in influence functions, we systematically develop K-FAC\\napproximations based on generalised Gauss-Newton matrices specifically tailored\\nto diffusion models. We recast previously proposed methods as specific design\\nchoices in our framework and show that our recommended method outperforms\\nprevious data attribution approaches on common evaluations, such as the Linear\\nData-modelling Score (LDS) or retraining without top influences, without the\\nneed for method-specific hyperparameter tuning.</td>\n",
              "      <td>[cs.LG, cs.AI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2024-10-17 17:59:01+00:00</td>\n",
              "      <td>From Gradient Clipping to Normalization for Heavy Tailed SGD</td>\n",
              "      <td>Recent empirical evidence indicates that many machine learning applications\\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\\nof bounded variance in stochastic optimization. Gradient clipping has emerged\\nas a popular tool to handle this heavy-tailed noise, as it achieves good\\nperformance in this setting both theoretically and practically. However, our\\ncurrent theoretical understanding of non-convex gradient clipping has three\\nmain shortcomings. First, the theory hinges on large, increasing clipping\\nthresholds, which are in stark contrast to the small constant clipping\\nthresholds employed in practice. Second, clipping thresholds require knowledge\\nof problem-dependent parameters to guarantee convergence. Lastly, even with\\nthis knowledge, current sampling complexity upper bounds for the method are\\nsub-optimal in nearly all parameters. To address these issues, we study\\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\\nsample complexity for NSGD of\\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\\nby providing a matching algorithm-specific lower bound. In the setting where\\nall problem parameters are known, we show this complexity is improved to\\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\\npreviously known lower bound for all first-order methods in all problem\\ndependent parameters. Finally, we establish high-probability convergence of\\nNSGD with a mild logarithmic dependence on the failure probability. Our work\\ncomplements the studies of gradient clipping under heavy tailed noise improving\\nthe sample complexities of existing algorithms and offering an alternative\\nmechanism to achieve high probability convergence.</td>\n",
              "      <td>[math.OC, cs.LG, stat.ML]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1305b876-892e-4f29-8915-c61c52da1782')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1305b876-892e-4f29-8915-c61c52da1782 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1305b876-892e-4f29-8915-c61c52da1782');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65cfb214-edf2-46f7-bfad-60a5b1a12e52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65cfb214-edf2-46f7-bfad-60a5b1a12e52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65cfb214-edf2-46f7-bfad-60a5b1a12e52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"published\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-10-17 17:59:01+00:00\",\n        \"max\": \"2024-10-17 17:59:59+00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2024-10-17 17:59:02+00:00\",\n          \"2024-10-17 17:59:55+00:00\",\n          \"2024-10-17 17:59:24+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Influence Functions for Scalable Data Attribution in Diffusion Models\",\n          \"VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding\",\n          \"Can MLLMs Understand the Deep Implication Behind Chinese Images?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Diffusion models have led to significant advancements in generative\\nmodelling. Yet their widespread adoption poses challenges regarding data\\nattribution and interpretability. In this paper, we aim to help address such\\nchallenges in diffusion models by developing an \\\\textit{influence functions}\\nframework. Influence function-based data attribution methods approximate how a\\nmodel's output would have changed if some training data were removed. In\\nsupervised learning, this is usually used for predicting how the loss on a\\nparticular example would change. For diffusion models, we focus on predicting\\nthe change in the probability of generating a particular example via several\\nproxy measurements. We show how to formulate influence functions for such\\nquantities and how previously proposed methods can be interpreted as particular\\ndesign choices in our framework. To ensure scalability of the Hessian\\ncomputations in influence functions, we systematically develop K-FAC\\napproximations based on generalised Gauss-Newton matrices specifically tailored\\nto diffusion models. We recast previously proposed methods as specific design\\nchoices in our framework and show that our recommended method outperforms\\nprevious data attribution approaches on common evaluations, such as the Linear\\nData-modelling Score (LDS) or retraining without top influences, without the\\nneed for method-specific hyperparameter tuning.\",\n          \"3D visual grounding is crucial for robots, requiring integration of natural\\nlanguage and 3D scene understanding. Traditional methods depending on\\nsupervised learning with 3D point clouds are limited by scarce datasets.\\nRecently zero-shot methods leveraging LLMs have been proposed to address the\\ndata issue. While effective, these methods only use object-centric information,\\nlimiting their ability to handle complex queries. In this work, we present\\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\\ndynamically stitches image sequences, employs a grounding and feedback scheme\\nto find the target object, and uses a multi-view ensemble projection to\\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\\ngeometry or object priors. Codes are available at\\nhttps://github.com/OpenRobotLab/VLM-Grounder .\",\n          \"As the capabilities of Multimodal Large Language Models (MLLMs) continue to\\nimprove, the need for higher-order capability evaluation of MLLMs is\\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\\nperception and understanding of Chinese visual content. To fill the gap, we\\nintroduce the **C**hinese **I**mage **I**mplication understanding\\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\\nout in several ways compared to existing benchmarks. Firstly, to ensure the\\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\\nChinese Internet and manually reviewed, with corresponding answers also\\nmanually crafted. Additionally, CII-Bench incorporates images that represent\\nChinese traditional culture, such as famous Chinese traditional paintings,\\nwhich can deeply reflect the model's understanding of Chinese traditional\\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\\nhave made significant findings. Initially, a substantial gap is observed\\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\\nculture images, suggesting limitations in their ability to understand\\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\\nculture. Finally, it is observed that most models exhibit enhanced accuracy\\nwhen image emotion hints are incorporated into the prompts. We believe that\\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\\nand Chinese-specific images, advancing the journey towards expert artificial\\ngeneral intelligence (AGI). Our project is publicly available at\\nhttps://cii-bench.github.io/.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Research paper summarizer\n",
        "from transformers import pipeline\n",
        "abstract = df['abstract'][0]\n",
        "\n",
        "summarizer = pipeline('summarization',model='facebook/bart-large-cnn')\n",
        "\n",
        "#summarization\n",
        "summarization_result = summarizer(abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "25dbac4304d9480480a0bbefc9f21646",
            "756792d44e464c32b1545ccc60a40623",
            "cea27340819f43acbca89149e7cf0dd8",
            "73bcaa5b4a964d0c80513d201f88e73b",
            "83e9e86eef7e4b0aabea6e7d887e5a67",
            "f8f646f105114ce39164217fd1f44eeb",
            "85395c7761284c4497c9aa39fe30c3e7",
            "0d189b139cf24f07b8e928189d502a48",
            "68b2666071bf4246988d7970e4ad7dc3",
            "024c1c19a2e04ebe8bf9efe26de6f431",
            "8fe5d2809a0f4c80a0f935798b52bc00",
            "ac49d22edf9b484eb0b839936d1fdf9e",
            "651c29eeaa42442ea23b70ddc9b4451c",
            "acc8cafdf3c6425c8ad0de3b301a338b",
            "0adaee8b45e74a0c956bc750230c1202",
            "dcf2fee199574c17b378a0dff91b1496",
            "972ea246efd8406a8dbf7ea0ed2cd20a",
            "1f1a98a088ef408391d0b015e5b2bf36",
            "c514d00b5df04911ad72edf8e1641573",
            "df9112360eec443c9924bb2ab9d2d7c0",
            "b3e50eac891a4331b6a7b15d6660f2fa",
            "48a6988319a04414a76e178d3e1614d2",
            "6d2e118e266e41a794b98670cf34b6b8",
            "ff75c20292b74afc99e1131278d48e66",
            "bb4378917d0c47f2b5b50d3616780d9a",
            "63285348262f49aabb60384c5e0901fb",
            "d95709ab1cc7431381f7b300bd4a538b",
            "98d1d1afa8a542eead184ac530b1af86",
            "c042312422284fe99b71520e1fab9d05",
            "9e808542319046c2b511f4304cbf37fd",
            "70816c52722745e5bc87cbba598450aa",
            "5410dd2959824c26828936ea2e76603f",
            "b9ad3c4f1d094918ad77e3da4804e8e3",
            "89a3e63d713a485386d1dadc0703009a",
            "81460e2f3ff042bc953d68eb24c7c9ab",
            "7dcf195e7c264f96948583477c8e6a7c",
            "bb3ea96f29a34fde89a54e58b2dc8f7c",
            "e15985be617e4133a503c435fac43918",
            "f24720e71ec2432f9d04315d25fe34d9",
            "87646379621748ec8b1f7c6b09d0a77b",
            "e825d2fc008b4821bb801f1b7f231554",
            "6e5b53dd12ec4988966e21fd79462a8b",
            "46df9358958e4547964ca9a1297c82ff",
            "f8fe978608ba47d9b8939f4f1602a7a0",
            "c1e12f9a30874de0bd9cbd2d0ca9d28c",
            "b298ebc6280249bc988399f4ed6293cf",
            "e648065b4ce145cebc71c212581a7491",
            "f2b85eca424545b6830ab07aa63ae7c6",
            "62b5c2750ed947629e18f6bf097198f5",
            "63a7f78d363a4c8fa1a79b81b039df6e",
            "ffed1af35cb74934a74dd09cea995877",
            "ee00c7fea4a74c4581932443771c5eed",
            "ea40a9a0cb9c4232ab6f69f8932d3000",
            "d6d61063ef814ebfb26a2aa1f33f9548",
            "b478776ca71a4e64a6b64e89b7c640c3",
            "5f77014c86b8460b96a14f70f93d04fc",
            "4cf44a4d03a34273aa3771b42acda1b5",
            "619425857d924afbb4f0314e6005afcc",
            "0f0f022961f445e4ac408907ef594b07",
            "a1e24b3197db4885b21fb103736d6af4",
            "5317495057ab41158c91e9652d8fd070",
            "42bcc8134f7e46f69bba3435d0d80b91",
            "1010db5ed70a4c5c93821f30d4d6827a",
            "e3d828f9ab1c424abaffb90fd587ebb2",
            "35e687b3d9864dbd97544efe65e4f9aa",
            "d547b2f9ebb047c5a9d73b0e0ceca14b"
          ]
        },
        "id": "ZYExFPUPc0JA",
        "outputId": "4dd37bd6-15fd-4067-a15a-ed8952277942"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25dbac4304d9480480a0bbefc9f21646"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac49d22edf9b484eb0b839936d1fdf9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d2e118e266e41a794b98670cf34b6b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89a3e63d713a485386d1dadc0703009a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e12f9a30874de0bd9cbd2d0ca9d28c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f77014c86b8460b96a14f70f93d04fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarization_result[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "a_aSgvy8de7O",
        "outputId": "1d4f0aa7-5e94-4095-e06a-9d8aab8f55c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Scaling up autoregressive models in vision has not proven as beneficial as in language models. Models based on continuous tokens achieve significantly better visual quality than those using discrete tokens. The generation order and attention mechanisms of random-order models significantly affect the GenEval score. We hope our findings will encourage future efforts to further bridge the gap between vision andlanguage models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYEMBwNjdtqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}